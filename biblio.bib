@article{Ghosh,
  author = {Ghosh, Sanjib},
  year = {2020},
  month = {10},
  pages = {},
  title = {Camillo Golgi (1843-1926): Scientist Extraordinaire and Pioneer Figure of Modern Neurology},
  volume = {53},
  journal = {Anatomy \& cell biology},
  doi = {10.5115/acb.20.196}
}

@ARTICLE{Nanami,
  AUTHOR={Nanami, Takuya and Kohno, Takashi},   
  TITLE={Piecewise quadratic neuron model: A tool for close-to-biology spiking neuronal network simulation on dedicated hardware},      
  JOURNAL={Frontiers in Neuroscience},      
  VOLUME={16},           
  YEAR={2023},       
  URL={https://www.frontiersin.org/articles/10.3389/fnins.2022.1069133},       
  DOI={10.3389/fnins.2022.1069133},      
  ISSN={1662-453X},
  ABSTRACT={Spiking neuron models simulate neuronal activities and allow us to analyze and reproduce the information processing of the nervous system. However, ionic-conductance models, which can faithfully reproduce neuronal activities, require a huge computational cost, while integral-firing models, which are computationally inexpensive, have some difficulties in reproducing neuronal activities. Here we propose a Piecewise Quadratic Neuron (PQN) model based on a qualitative modeling approach that aims to reproduce only the key dynamics behind neuronal activities. We demonstrate that PQN models can accurately reproduce the responses of ionic-conductance models of major neuronal classes to stimulus inputs of various magnitudes. In addition, the PQN model is designed to support the efficient implementation on digital arithmetic circuits for use as silicon neurons, and we confirm that the PQN model consumes much fewer circuit resources than the ionic-conductance models. This model intends to serve as a tool for building a large-scale closer-to-biology spiking neural network.}
}

@article{Hoeneisen,
  title = {Fundamental limitations in microelectronics—I. MOS technology},
  journal = {Solid-State Electronics},
  volume = {15},
  number = {7},
  pages = {819-829},
  year = {1972},
  issn = {0038-1101},
  doi = {https://doi.org/10.1016/0038-1101(72)90103-7},
  url = {https://www.sciencedirect.com/science/article/pii/0038110172901037},
  author = {B. Hoeneisen and C.A. Mead},
  abstract = {The physical phenomena which will ultimately limit MOS circuit miniaturization are considered. It is found that the minimum MOS transistor size is determined by gate oxide breakdown and drain-source punch-through. Other factors which limit device size are drain-substrate breakdown, drain ‘corner’ breakdown and substrate doping fluctuations. However these limitations are less severe than the oxide breakdown limitation mentioned above. Power dissipation and metal migration limit the frequency and/or packing density of fully dynamic and of complementary MOS circuits. In static non-complementary circuits, power dissipation is the principal limitation of the number of circuit functions per chip. The channel length of a minimum size MOS transistor is a factor of 10 smaller than that of the smallest present day devices. The tolerances required to manufacture such a transistor are compatible with electron beam masking techniques. It is thus possible to envision fully dynamic silicon chips with up to 107–108 MOS transistors per cm2.}
}

@ARTICLE{Moore,
  author={Moore, Gordon E.},
  journal={IEEE Solid-State Circuits Society Newsletter}, 
  title={Cramming more components onto integrated circuits, Reprinted from Electronics, volume 38, number 8, April 19, 1965, pp.114 ff.}, 
  year={2006},
  volume={11},
  number={3},
  pages={33-35},
  doi={10.1109/N-SSC.2006.4785860}}

@article{Shalf,
author = {Shalf, John },
title = {The future of computing beyond Moore’s Law},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
volume = {378},
number = {2166},
pages = {20190061},
year = {2020},
doi = {10.1098/rsta.2019.0061},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2019.0061},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2019.0061},
abstract = { Moore’s Law is a techno-economic model that has enabled the information technology industry to double the performance and functionality of digital electronics roughly every 2 years within a fixed cost, power and area. Advances in silicon lithography have enabled this exponential miniaturization of electronics, but, as transistors reach atomic scale and fabrication costs continue to rise, the classical technological driver that has underpinned Moore’s Law for 50 years is failing and is anticipated to flatten by 2025. This article provides an updated view of what a post-exascale system will look like and the challenges ahead, based on our most recent understanding of technology roadmaps. It also discusses the tapering of historical improvements, and how it affects options available to continue scaling of successors to the first exascale machine. Lastly, this article covers the many different opportunities and strategies available to continue computing performance improvements in the absence of historical technology drivers. This article is part of a discussion meeting issue ‘Numerical algorithms for high-performance computational science’. }
}

@ARTICLE{Mead1990,
  author={Mead, C.},
  journal={Proceedings of the IEEE}, 
  title={Neuromorphic electronic systems}, 
  year={1990},
  volume={78},
  number={10},
  pages={1629-1636},
  abstract={It is shown that for many problems, particularly those in which the input data are ill-conditioned and the computation can be specified in a relative manner, biological solutions are many orders of magnitude more effective than those using digital methods. This advantage can be attributed principally to the use of elementary physical phenomena as computational primitives, and to the representation of information by the relative values of analog signals rather than by the absolute values of digital signals. This approach requires adaptive techniques to mitigate the effects of component differences. This kind of adaptation leads naturally to systems that learn about their environment. Large-scale adaptive analog systems are more robust to component degradation and failure than are more conventional systems, and they use far less power. For this reason, adaptive analog technology can be expected to utilize the full potential of wafer-scale silicon fabrication.<>},
  keywords={},
  doi={10.1109/5.58356},
  ISSN={1558-2256},
  month={10},}

@ARTICLE{Frenkel2023,
  author={Frenkel, Charlotte and Bol, David and Indiveri, Giacomo},
  journal={Proceedings of the IEEE}, 
  title={Bottom-Up and Top-Down Approaches for the Design of Neuromorphic Processing Systems: Tradeoffs and Synergies Between Natural and Artificial Intelligence}, 
  year={2023},
  volume={111},
  number={6},
  pages={623-652},
  doi={10.1109/JPROC.2023.3273520}}

@article{DeVries,
title = {The growing energy footprint of artificial intelligence},
journal = {Joule},
volume = {7},
number = {10},
pages = {2191-2194},
year = {2023},
issn = {2542-4351},
doi = {https://doi.org/10.1016/j.joule.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2542435123003653},
author = {Alex {de Vries}},
abstract = {Alex de Vries is a PhD candidate at the VU Amsterdam School of Business and Economics and the founder of Digiconomist, a research company dedicated to exposing the unintended consequences of digital trends. His research focuses on the environmental impact of emerging technologies and has played a major role in the global discussion regarding the sustainability of blockchain technology.}
}

@article{Mead2023,
    author = {Mead, Carver},
    title = "{Neuromorphic Engineering: In Memory of Misha Mahowald}",
    journal = {Neural Computation},
    volume = {35},
    number = {3},
    pages = {343-383},
    year = {2023},
    month = {02},
    abstract = "{We review the coevolution of hardware and software dedicated to neuromorphic systems. From modest beginnings, these disciplines have become central to the larger field of computation. In the process, their biological foundations become more relevant, and their realizations increasingly overlap. We identify opportunities for significant steps forward in both the near and more distant future.}",
    issn = {0899-7667},
    doi = {10.1162/neco_a_01553},
    url = {https://doi.org/10.1162/neco\_a\_01553},
    eprint = {https://direct.mit.edu/neco/article-pdf/35/3/343/2072229/neco\_a\_01553.pdf},
}

@article{Sandin,
title = {Concept Learning in Neuromorphic Vision Systems: What Can We Learn from Insects?},
abstract = {Vision systems that enable collision avoidance, localization and navigation in complex and uncertain environments are common in biology, but are extremely challenging to mimic in artificial electronic systems, in particular when size and power limitations apply. The development of neuromorphic electronic systems implementing models of biological sensory-motor systems in silicon is one promising approach to addressing these challenges. Concept learning is a central part of animal cognition that enables appropriate motor response in novel situations by generalization of former experience, possibly from a few examples. These aspects make concept learning a challenging and important problem. Learning methods in computer vision are typically inspired by mammals, but recent studies of insects motivate an interesting complementary research direction. There are several remarkable results showing that honeybees can learn to master abstract concepts, providing a road map for future work to allow direct comparisons between bio-inspired computing architectures and information processing in miniaturized “real” brains. Considering that the brain of a bee has less than 0.01\% as many neurons as a human brain, the task to infer a minimal architecture and mechanism of concept learning from studies of bees appears well motivated. The relatively low complexity of insect sensory-motor systems makes them an interesting model for the further development of bio-inspired computing architectures, in particular for resource-constrained applications such as miniature robots, wireless sensors and handheld or wearable devices. Work in that direction is a natural step towards understanding and making use of prototype circuits for concept learning, which eventually may also help us to understand the more complex learning circuits of the human brain. By adapting concept learning mechanisms to a polymorphic computing framework we could possibly create large-scale decentralized computer vision systems, for example in the form of wireless sensor networks.},
address = {United States},
author = {Sandin, Fredrik and Khan, Asad and Dyer, Adrian and Amin, Anang and Indiveri, Giacomo and Chicca, Elisabetta and Osipov, Evgeny},
issn = {1945-3116},
journal = {Journal of Software Engineering and Applications},
keywords = {Concept Learning;Computer Vision;Computer Architecture;Neuromorphic Engineering;Insect},
language = {eng},
pages = {9},
publisher = {Scientific Research Publishing},
volume = {7},
year = {2014},
}

@article{IndiveriLiu,
  title={Memory and Information Processing in Neuromorphic Systems},
  author={G. Indiveri and Shih-Chii Liu},
  journal={Proceedings of the IEEE},
  year={2015},
  volume={103},
  pages={1379-1397},
  url={https://api.semanticscholar.org/CorpusID:13984215}
}

@ARTICLE{Levi2018,
  author={Levi, Timothée and Nanami, Takuya and Tange, Atsuya and Aihara, Kazuyuki and Kohno, Takashi},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={Development and Applications of Biomimetic Neuronal Networks Toward BrainMorphic Artificial Intelligence}, 
  year={2018},
  volume={65},
  number={5},
  pages={577-581},
  doi={10.1109/TCSII.2018.2824827}}

@ARTICLE{Ambroise,
AUTHOR={Ambroise, Matthieu and Levi, Timothée and Joucla, Sébastien and Yvert, Blaise and Saïghi, Sylvain},   
TITLE={Real-time biomimetic Central Pattern Generators in an FPGA for hybrid experiments},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={7},           
YEAR={2013},      
URL={https://www.frontiersin.org/articles/10.3389/fnins.2013.00215},       
DOI={10.3389/fnins.2013.00215},      
ISSN={1662-453X},   
ABSTRACT={This investigation of the leech heartbeat neural network system led to the development of a low resources, real-time, biomimetic digital hardware for use in hybrid experiments. The leech heartbeat neural network is one of the simplest central pattern generators (CPG). In biology, CPG provide the rhythmic bursts of spikes that form the basis for all muscle contraction orders (heartbeat) and locomotion (walking, running, etc.). The leech neural network system was previously investigated and this CPG formalized in the Hodgkin–Huxley neural model (HH), the most complex devised to date. However, the resources required for a neural model are proportional to its complexity. In response to this issue, this article describes a biomimetic implementation of a network of 240 CPGs in an FPGA (Field Programmable Gate Array), using a simple model (Izhikevich) and proposes a new synapse model: activity-dependent depression synapse. The network implementation architecture operates on a single computation core. This digital system works in real-time, requires few resources, and has the same bursting activity behavior as the complex model. The implementation of this CPG was initially validated by comparing it with a simulation of the complex model. Its activity was then matched with pharmacological data from the rat spinal cord activity. This digital system opens the way for future hybrid experiments and represents an important step toward hybridization of biological tissue and artificial neural networks. This CPG network is also likely to be useful for mimicking the locomotion activity of various animals and developing hybrid experiments for neuroprosthesis development.}
}

@article{Pospischil,
author = {Pospischil, Martin and Toledo-Rodriguez, Maria and Monier, Cyril and Piwkowska, Zuzanna and Bal, Thierry and Frégnac, Yves and Markram, Henry and Destexhe, Alain},
year = {2008},
month = {12},
pages = {427-41},
title = {Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons},
volume = {99},
journal = {Biological cybernetics},
doi = {10.1007/s00422-008-0263-8}
}

@article{Lengler,
    doi = {10.1371/journal.pone.0080694},
    author = {Lengler, Johannes AND Jug, Florian AND Steger, Angelika},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Reliable Neuronal Systems: The Importance of Heterogeneity},
    year = {2013},
    month = {12},
    volume = {8},
    url = {https://doi.org/10.1371/journal.pone.0080694},
    pages = {1-10},
    abstract = {For every engineer it goes without saying: in order to build a reliable system we need components that consistently behave precisely as they should. It is also well known that neurons, the building blocks of brains, do not satisfy this constraint. Even neurons of the same type come with huge variances in their properties and these properties also vary over time. Synapses, the connections between neurons, are highly unreliable in forwarding signals. In this paper we argue that both these fact add variance to neuronal processes, and that this variance is not a handicap of neural systems, but that instead predictable and reliable functional behavior of neural systems depends crucially on this variability. In particular, we show that higher variance allows a recurrently connected neural population to react more sensitively to incoming signals, and processes them faster and more energy efficient. This, for example, challenges the general assumption that the intrinsic variability of neurons in the brain is a defect that has to be overcome by synaptic plasticity in the process of learning.},
    number = {12},
}

@book{Pellerin,
author = {Pellerin, David and Taylor, Douglas},
title = {VHDL Made Easy!},
year = {1997},
isbn = {0136507638},
publisher = {Prentice-Hall, Inc.},
address = {USA}
}

@incollection{WILSON,
title = {Introduction},
editor = {Peter Wilson},
booktitle = {Design Recipes for FPGAs (Second Edition)},
publisher = {Newnes},
edition = {Second Edition},
address = {Oxford},
pages = {65},
year = {2016},
isbn = {978-0-08-097129-2},
doi = {https://doi.org/10.1016/B978-0-08-097129-2.09983-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080971292099839},
author = {Peter Wilson}
}

@article{Jessen,
title = {Glial cells},
journal = {The International Journal of Biochemistry \& Cell Biology},
volume = {36},
number = {10},
pages = {1861-1867},
year = {2004},
issn = {1357-2725},
doi = {https://doi.org/10.1016/j.biocel.2004.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S1357272504000846},
author = {Kristjan R Jessen},
keywords = {Nervous system, Astrocytes, Oligodendrocytes, Schwann cells},
abstract = {The nervous system is built from two broad categories of cells, neurones and glial cells. The glial cells outnumber the neurones and the two cell types occupy a comparable amount of space in nervous tissue. The main glial cell types are, in the central nervous system, astrocytes and oligodendrocytes and, in the peripheral nervous system, Schwann cells, enteric glial cells and satellite cells. In the embryo, glial cells form a cellular framework that permits the development of the rest of the nervous system, and regulate neuronal survival and differentiation. The best known function of glia in the adult is the formation of myelin sheaths around axons thus allowing the fast conduction of signalling essential for nervous system function. Glia also maintain appropriate concentrations of ions and neurotransmitters in the neuronal environment. Increasing body of evidence indicates that glial cells are essential regulators of the formation, maintenance and function of synapses, the key functional unit of the nervous system.Cell facts•Throughout the brain, spinal cord and peripheral nerves, neurones are never found except in a close association with glial cells.•The turnover rate of mature glia is normally close to zero but most of them respond to injury by rapid proliferation.•Glial cells come in many types and have multiple functions in the developing and mature nervous system.•Following injury, glia are major regulators of neuronal repair and they are largely responsible for the difference in regeneration capacity between the central and peripheral nervous system.}
}

@book{Dayan,
  added-at = {2014-10-19T18:26:49.000+0200},
  address = {Cambridge, MA},
  author = {Dayan, P. and Abbott, L.F.},
  biburl = {https://www.bibsonomy.org/bibtex/276708ec0787e8ff87af00d51dbf54e6f/prlz77},
  interhash = {de1e50cb92a17fe14657777b31319d55},
  intrahash = {76708ec0787e8ff87af00d51dbf54e6f},
  keywords = {Abbott Dayan L.F. Neuroscience P. Theoretical},
  publisher = {MIT Press},
  timestamp = {2014-10-19T18:26:49.000+0200},
  title = {Theoretical Neuroscience},
  year = 2001
}

@book{Koch2004,
  author = {Koch, Christof},
  title = {Biophysics of Computation: Information Processing in Single Neurons  (Computational Neuroscience Series)},
  year = {2004},
  isbn = {0195181999},
  publisher = {Oxford University Press, Inc.},
  address = {USA}
}

@article{Lapicque,
  added-at = {2014-01-19T06:59:12.000+0100},
  author = {Lapicque, Louis},
  biburl = {https://www.bibsonomy.org/bibtex/2a436d5d569937a52c3b85951dfcc2733/neurokernel},
  interhash = {41afa3d20bb21eea2d3748428020a16a},
  intrahash = {a436d5d569937a52c3b85951dfcc2733},
  journal = {J. Physiol. Pathol. Gen.},
  keywords = {neuron},
  pages = {620--635},
  timestamp = {2014-01-19T06:59:12.000+0100},
  title = {Recherches quantitatives sur l'excitation {\'e}lectrique des nerfs trait{\'e}e comme une polarisation},
  volume = 9,
  year = 1907
}

@article{Abbott1999,
  title={Lapicque’s introduction of the integrate-and-fire model neuron (1907)},
  author={L.F Abbott},
  journal={Brain Research Bulletin},
  year={1999},
  volume={50},
  pages={303-304},
  url={https://api.semanticscholar.org/CorpusID:46170924}
}

@article{Tuckwell,
author = {Tuckwell, Henry},
year = {1998},
month = {11},
pages = {223-8},
title = {Continuum models in neurobiology and information processing},
volume = {48},
journal = {Bio Systems},
doi = {10.1016/S0303-2647(98)00069-0}
}

@article {Burkitt,
	Title = {A review of the integrate-and-fire neuron model: I. Homogeneous synaptic input},
	Author = {Burkitt, AN},
	DOI = {10.1007/s00422-006-0068-6},
	Number = {1},
	Volume = {95},
	Month = {6},
	Year = {2006},
	Journal = {Biological cybernetics},
	ISSN = {0340-1200},
	Pages = {1—19},
	Abstract = {The integrate-and-fire neuron model is one of the most widely used models for analyzing the behavior of neural systems. It describes the membrane potential of a neuron in terms of the synaptic inputs and the injected current that it receives. An action potential (spike) is generated when the membrane potential reaches a threshold, but the actual changes associated with the membrane voltage and conductances driving the action potential do not form part of the model. The synaptic inputs to the neuron are considered to be stochastic and are described as a temporally homogeneous Poisson process. Methods and results for both current synapses and conductance synapses are examined in the diffusion approximation, where the individual contributions to the postsynaptic potential are small. The focus of this review is upon the mathematical techniques that give the time distribution of output spikes, namely stochastic differential equations and the Fokker-Planck equation. The integrate-and-fire neuron model has become established as a canonical model for the description of spiking neurons because it is capable of being analyzed mathematically while at the same time being sufficiently complex to capture many of the essential features of neural processing. A number of variations of the model are discussed, together with the relationship with the Hodgkin-Huxley neuron model and the comparison with electrophysiological data. A brief overview is given of two issues in neural information processing that the integrate-and-fire neuron model has contributed to - the irregular nature of spiking in cortical neurons and neural gain modulation.},
	URL = {https://doi.org/10.1007/s00422-006-0068-6},
}

@article{Zheng,
author = {Zheng, Gang and Tonnelier, Arnaud},
year = {2008},
month = {12},
pages = {197-204},
title = {Chaotic solutions in the quadratic integrate-and-fire neuron with adaptation},
volume = {3},
journal = {Cognitive neurodynamics},
doi = {10.1007/s11571-008-9069-6}
}

@article {FourcaudTrocme,
	author = {Nicolas Fourcaud-Trocm{\'e} and David Hansel and Carl van Vreeswijk and Nicolas Brunel},
	title = {How Spike Generation Mechanisms Determine the Neuronal Response to Fluctuating Inputs},
	volume = {23},
	number = {37},
	pages = {11628--11640},
	year = {2003},
	doi = {10.1523/JNEUROSCI.23-37-11628.2003},
	publisher = {Society for Neuroscience},
	abstract = {This study examines the ability of neurons to track temporally varying inputs, namely by investigating how the instantaneous firing rate of a neuron is modulated by a noisy input with a small sinusoidal component with frequency (f). Using numerical simulations of conductance-based neurons and analytical calculations of one-variable nonlinear integrate-and-fire neurons, we characterized the dependence of this modulation on f. For sufficiently high noise, the neuron acts as a low-pass filter. The modulation amplitude is approximately constant for frequencies up to a cutoff frequency, fc, after which it decays. The cutoff frequency increases almost linearly with the firing rate. For higher frequencies, the modulation amplitude decays as C/fα, where the power α depends on the spike initiation mechanism. For conductance-based models, α = 1, and the prefactor C depends solely on the average firing rate and a spike {\textquotedblleft}slope factor,{\textquotedblright} which determines the sharpness of the spike initiation. These results are attributable to the fact that near threshold, the sodium activation variable can be approximated by an exponential function. Using this feature, we propose a simplified one-variable model, the {\textquotedblleft}exponential integrate-and-fire neuron,{\textquotedblright} as an approximation of a conductance-based model. We show that this model reproduces the dynamics of a simple conductance-based model extremely well. Our study shows how an intrinsic neuronal property (the characteristics of fast sodium channels) determines the speed with which neurons can track changes in input.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/23/37/11628},
	eprint = {https://www.jneurosci.org/content/23/37/11628.full.pdf},
	journal = {Journal of Neuroscience}
}

@article{Smith,
author = {Smith, Gregory D. and Cox, Charles L. and Sherman, S. Murray and Rinzel, John},
title = {Fourier Analysis of Sinusoidally Driven Thalamocortical Relay Neurons and a Minimal Integrate-and-Fire-or-Burst Model},
journal = {Journal of Neurophysiology},
volume = {83},
number = {1},
pages = {588-610},
year = {2000},
doi = {10.1152/jn.2000.83.1.588},
note ={PMID: 10634897},
URL = {https://doi.org/10.1152/jn.2000.83.1.588},
eprint = {https://doi.org/10.1152/jn.2000.83.1.588},
abstract = { We performed intracellular recordings of relay neurons from the lateral geniculate nucleus of a cat thalamic slice preparation. We measured responses during both tonic and burst firing modes to sinusoidal current injection and performed Fourier analysis on these responses. For comparison, we constructed a minimal “integrate-and-fire-or-burst” (IFB) neuron model that reproduces salient features of the relay cell responses. The IFB model is constrained to quantitatively fit our Fourier analysis of experimental relay neuron responses, including: the temporal tuning of the response in both tonic and burst modes, including a finding of low-pass and sometimes broadband behavior of tonic firing and band-pass characteristics during bursting, and the generally greater linearity of tonic compared with burst responses at low frequencies. In tonic mode, both experimental and theoretical responses display a frequency-dependent transition from massively superharmonic spiking to phase-locked superharmonic spiking near 3 Hz, followed by phase-locked subharmonic spiking at higher frequencies. Subharmonic and superharmonic burst responses also were observed experimentally. Characterizing the response properties of the “tuned” IFB model leads to insights regarding the observed stimulus dependence of burst versus tonic response mode in relay neurons. Furthermore the simplicity of the IFB model makes it a candidate for large scale network simulations of thalamic functioning. }
}

@article{Brette,
author = {Brette, Romain and Gerstner, Wulfram},
title = {Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity},
journal = {Journal of Neurophysiology},
volume = {94},
number = {5},
pages = {3637-3642},
year = {2005},
doi = {10.1152/jn.00686.2005},
note ={PMID: 16014787},
URL = {https://doi.org/10.1152/jn.00686.2005},
eprint = {https://doi.org/10.1152/jn.00686.2005},
abstract = { We introduce a two-dimensional integrate-and-fire model that combines an exponential spike mechanism with an adaptation equation, based on recent theoretical findings. We describe a systematic method to estimate its parameters with simple electrophysiological protocols (current-clamp injection of pulses and ramps) and apply it to a detailed conductance-based model of a regular spiking neuron. Our simple model predicts correctly the timing of 96\% of the spikes (±2 ms) of the detailed model in response to injection of noisy synaptic conductances. The model is especially reliable in high-conductance states, typical of cortical activity in vivo, in which intrinsic conductances were found to have a reduced role in shaping spike trains. These results are promising because this simple model has enough expressive power to reproduce qualitatively several electrophysiological classes described in vitro. }
}

@ARTICLE{IZH,
  author={Izhikevich, E.M.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Simple model of spiking neurons}, 
  year={2003},
  volume={14},
  number={6},
  pages={1569-1572},
  doi={10.1109/TNN.2003.820440}}

@article{Hendrickson,
author = {Hendrickson, Eric and Edgerton, Jeremy and Jaeger, Dieter},
year = {2011},
month = {04},
pages = {301-21},
title = {The capabilities and limitations of conductance-based compartmental neuron models with reduced branched or unbranched morphologies and active dendrites},
volume = {30},
journal = {Journal of computational neuroscience},
doi = {10.1007/s10827-010-0258-z}
}

@article{HH,
author = {Hodgkin, A. L. and Huxley, A. F.},
title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
journal = {The Journal of Physiology},
volume = {117},
number = {4},
pages = {500-544},
doi = {https://doi.org/10.1113/jphysiol.1952.sp004764},
url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1952.sp004764},
eprint = {https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1952.sp004764},
year = {1952}
}

@article{FitzHugh,
title = {Impulses and Physiological States in Theoretical Models of Nerve Membrane},
journal = {Biophysical Journal},
volume = {1},
number = {6},
pages = {445-466},
year = {1961},
issn = {0006-3495},
doi = {https://doi.org/10.1016/S0006-3495(61)86902-6},
url = {https://www.sciencedirect.com/science/article/pii/S0006349561869026},
author = {Richard FitzHugh},
abstract = {Van der Pol's equation for a relaxation oscillator is generalized by the addition of terms to produce a pair of non-linear differential equations with either a stable singular point or a limit cycle. The resulting “BVP model” has two variables of state, representing excitability and refractoriness, and qualitatively resembles Bonhoeffer's theoretical model for the iron wire model of nerve. This BVP model serves as a simple representative of a class of excitable-oscillatory systems including the Hodgkin-Huxley (HH) model of the squid giant axon. The BVP phase plane can be divided into regions corresponding to the physiological states of nerve fiber (resting, active, refractory, enhanced, depressed, etc.) to form a “physiological state diagram,” with the help of which many physiological phenomena can be summarized. A properly chosen projection from the 4-dimensional HH phase space onto a plane produces a similar diagram which shows the underlying relationship between the two models. Impulse trains occur in the BVP and HH models for a range of constant applied currents which make the singular point representing the resting state unstable.}
}

@ARTICLE{Nagumo,
  author={Nagumo, J. and Arimoto, S. and Yoshizawa, S.},
  journal={Proceedings of the IRE}, 
  title={An Active Pulse Transmission Line Simulating Nerve Axon}, 
  year={1962},
  volume={50},
  number={10},
  pages={2061-2070},
  doi={10.1109/JRPROC.1962.288235}}

@book{Strogatz,
  added-at = {2010-05-11T11:15:46.000+0200},
  author = {Strogatz, Steven H.},
  biburl = {https://www.bibsonomy.org/bibtex/2e3b3dc5a68df87d71becbe75709a7121/flashbang},
  citeulike-article-id = {6778211},
  interhash = {097881c5ab43732a75182222236e72c7},
  intrahash = {e3b3dc5a68df87d71becbe75709a7121},
  keywords = {chaos dynamical-systems nonlinear},
  posted-at = {2010-03-08 21:41:28},
  priority = {2},
  publisher = {Westview Press},
  timestamp = {2010-05-11T11:16:46.000+0200},
  title = {Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering},
  year = 2000
}

@article{Kepler,
author = {Kepler, Thomas and Abbott, L and Marder, Eve},
year = {1992},
month = {02},
pages = {381-7},
title = {Reduction of conductance-based neuron models},
volume = {66},
journal = {Biological cybernetics},
doi = {10.1007/BF00197717}
}

@article{Rinzel,
author = {Rinzel, John and Ermentrout, Bard},
year = {1998},
month = {01},
pages = {},
title = {Analysis of Neural Excitability and Oscillations},
journal = {Methods of Neuronal Modeling}
}

@article{Izhikevich2007,
  added-at = {2009-11-12T16:21:13.000+0100},
  author = {Izhikevich, E},
  biburl = {https://www.bibsonomy.org/bibtex/28f51feb262d765cafb6ae62142083859/fdiehl},
  date-added = {2008-01-08 18:07:44 +0100},
  date-modified = {2009-11-10 09:45:34 +0100},
  description = {bib-komplett},
  interhash = {acbc8f70e45699e202ec919c200d7106},
  intrahash = {8f51feb262d765cafb6ae62142083859},
  journal = {MIT Press},
  keywords = {imported},
  local-url = {file://localhost/Neurobio/Papers/Untitled-p75.pdf},
  month = Jul,
  pages = 111,
  rating = {0},
  read = {Yes},
  timestamp = {2009-11-12T16:21:28.000+0100},
  title = {Dynamical Systems In Neuroscience},
  uri = {papers://7B65697B-E216-4648-8A41-C67830C0DC73/Paper/p75},
  year = 2007
}

@article{Cunningham,
          volume = {101},
          number = {18},
           month = {5},
          author = {M.O. Cunningham and M.A. Whittington and A. Bibbig and A. Roopun and F.E.N. LeBeau and A. Vogt and H. Monyer and E.H. Buhl and R.D. Traub},
            note = {Copyright {\copyright} 2004 by the National Academy of Sciences},
           title = {A role for fast rhythmic bursting neurons in cortical gamma oscillations in vitro },
            year = {2004},
         journal = {Prcoeedings of the National Academy of Sciences},
           pages = {7152--7157},
             url = {https://eprints.whiterose.ac.uk/563/},
        abstract = {Basic cellular and network mechanisms underlying gamma frequency oscillations (30?80 Hz) have been well characterized in the hippocampus and associated structures. In these regions, gamma rhythms are seen as an emergent property of networks of principal cells and fast-spiking interneurons. In contrast, in the neocortex a number of elegant studies have shown that specific types of principal neuron exist that are capable of generating powerful gamma frequency outputs on the basis of their intrinsic conductances alone. These fast rhythmic bursting (FRB) neurons (sometimes referred to as "chattering" cells) are activated by sensory stimuli and generate multiple action potentials per gamma period. Here, we demonstrate that FRB neurons may function by providing a large-scale input to an axon plexus consisting of gap-junctionally connected axons from both FRB neurons and their anatomically similar counterparts regular spiking neurons. The resulting network gamma oscillation shares all of the properties of gamma oscillations generated in the hippocampus but with the additional critical dependence on multiple spiking in FRB cells. 
}
}

@article{Benda,
author = {Benda, Jan and Longtin, Andre and Maler, Len},
year = {2005},
month = {04},
pages = {2312-21},
title = {Spike-Frequency Adaptation Separates Transient Communication Signals from Background Oscillations},
volume = {25},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
doi = {10.1523/JNEUROSCI.4795-04.2005}
}

@article{GRILLNER,
title = {Biological Pattern Generation: The Cellular and Computational Logic of Networks in Motion},
journal = {Neuron},
volume = {52},
number = {5},
pages = {751-766},
year = {2006},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2006.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0896627306009020},
author = {Sten Grillner},
abstract = {In 1900, Ramón y Cajal advanced the neuron doctrine, defining the neuron as the fundamental signaling unit of the nervous system. Over a century later, neurobiologists address the circuit doctrine: the logic of the core units of neuronal circuitry that control animal behavior. These are circuits that can be called into action for perceptual, conceptual, and motor tasks, and we now need to understand whether there are coherent and overriding principles that govern the design and function of these modules. The discovery of central motor programs has provided crucial insight into the logic of one prototypic set of neural circuits: those that generate motor patterns. In this review, I discuss the mode of operation of these pattern generator networks and consider the neural mechanisms through which they are selected and activated. In addition, I will outline the utility of computational models in analysis of the dynamic actions of these motor networks.}
}

@article{Alle,
author = {Alle, Henrik and Geiger, Jörg},
year = {2006},
month = {04},
pages = {1290-3},
title = {Combined Analog and Action Potential Coding in Hippocampal Mossy Fibers},
volume = {311},
journal = {Science (New York, N.Y.)},
doi = {10.1126/science.1119055}
}

@article{Hodgkin,
author = {Hodgkin, A. L.},
title = {The local electric changes associated with repetitive action in a non-medullated axon},
journal = {The Journal of Physiology},
volume = {107},
number = {2},
pages = {165-181},
doi = {https://doi.org/10.1113/jphysiol.1948.sp004260},
url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1948.sp004260},
eprint = {https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1948.sp004260},
year = {1948}
}

@article{Hindmarsh,
author = {Hindmarsh, James and Rose, R},
year = {1984},
month = {04},
pages = {87-102},
title = {A Model of Neuronal Bursting Using Three Coupled First Order Differential Equations},
volume = {221},
journal = {Proceedings of the Royal Society of London. Series B, Containing papers of a Biological character. Royal Society (Great Britain)},
doi = {10.1098/rspb.1984.0024}
}

@ARTICLE{Nanami2016,
AUTHOR={Nanami, Takuya and Kohno, Takashi},   
TITLE={Simple Cortical and Thalamic Neuron Models for Digital Arithmetic Circuit Implementation},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={10},           
YEAR={2016},        
URL={https://www.frontiersin.org/articles/10.3389/fnins.2016.00181},     
DOI={10.3389/fnins.2016.00181},      
ISSN={1662-453X},   
ABSTRACT={Trade-off between reproducibility of neuronal activities and computational efficiency is one of crucial subjects in computational neuroscience and neuromorphic engineering. A wide variety of neuronal models have been studied from different viewpoints. The digital spiking silicon neuron (DSSN) model is a qualitative model that focuses on efficient implementation by digital arithmetic circuits. We expanded the DSSN model and found appropriate parameter sets with which it reproduces the dynamical behaviors of the ionic-conductance models of four classes of cortical and thalamic neurons. We first developed a four-variable model by reducing the number of variables in the ionic-conductance models and elucidated its mathematical structures using bifurcation analysis. Then, expanded DSSN models were constructed that reproduce these mathematical structures and capture the characteristic behavior of each neuron class. We confirmed that statistics of the neuronal spike sequences are similar in the DSSN and the ionic-conductance models. Computational cost of the DSSN model is larger than that of the recent sophisticated Integrate-and-Fire-based models, but smaller than the ionic-conductance models. This model is intended to provide another meeting point for above trade-off that satisfies the demand for large-scale neuronal network simulation with closer-to-biology models.}
}

@article{CONNORS,
title = {Intrinsic firing patterns of diverse neocortical neurons},
journal = {Trends in Neurosciences},
volume = {13},
number = {3},
pages = {99-104},
year = {1990},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(90)90185-D},
url = {https://www.sciencedirect.com/science/article/pii/016622369090185D},
author = {Barry W. Connors and Michael J. Gutnick},
abstract = {Neurons of the neocortex differ dramatically in the patterns of action potentials they generate in response to current steps. Regular-spiking cells adapt strongly during maintained stimuli, whereas fast-spiking cells can sustain very high firing frequencies with little or no adaptation. Instrinsically bursting cells generate clusters of spikes (bursts), either singly or repetitively. These physiological distinctions have morphological correlates. RS and IB cells can be either pyramidal neurons or spiny stellate cells, and thus constitute the excitatory cells of the cortex. FS cells are smooth or sparsely spiny non-pyramidal cells, and are likely to be GABAergic inhibitory interneurons. The different firing properties of neurons in neocortex contribute significantly to its network behavior.}
}

@article{Izhikevich1999,
 ISSN = {00361399},
 URL = {http://www.jstor.org/stable/118493},
 abstract = {Bursting behavior in neurons is a recurrent transition between a quiescent state and repetitive spiking. When the transition to repetitive spiking occurs via a subcritical Andronov-Hopf bifurcation and the transition to the quiescent state occurs via double limit cycle bifurcation, the burster is said to be of subcritical elliptic type. When the fast subsystem is near a Bautin (generalized Hopf) point, both bifurcations occur for nearby values of the slow variable, and the repetitive spiking has small amplitude. We refer to such an elliptic burster as being of local Bautin type. First, we prove that any such burster can be converted into a canonical model by a suitable continuous (possibly noninvertible) change of variables. We also derive a canonical model for weakly connected networks of such bursters. We find that behavior of such networks is quite different from the behavior of weakly connected phase oscillators, and it resembles that of strongly connected relaxation oscillators. As a result, such weakly connected bursters need few (usually one) bursts to synchronize. In-phase synchronization is possible for bursters having quite different quantitative features, whereas out-of-phase synchronization may be difficult to achieve. We also find that interactions between bursters depend crucially on the spiking frequencies. Namely, the interactions are most effective when the presynaptic interspike frequency matches the frequency of postsynaptic oscillations. Finally, we use the FitzHugh-Rinzel model to evaluate how studying local Bautin bursters can contribute to our understanding of the phenomena of subcritical elliptic bursting.},
 author = {Eugene M. Izhikevich},
 journal = {SIAM Journal on Applied Mathematics},
 number = {2},
 pages = {503--535},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Subcritical Elliptic Bursting of Bautin Type},
 urldate = {2023-12-01},
 volume = {60},
 year = {1999}
}

@article {DestexheLTS,
	author = {Alain Destexhe and Mike Neubig and Daniel Ulrich and John Huguenard},
	title = {Dendritic Low-Threshold Calcium Currents in Thalamic Relay Cells},
	volume = {18},
	number = {10},
	pages = {3574--3588},
	year = {1998},
	doi = {10.1523/JNEUROSCI.18-10-03574.1998},
	publisher = {Society for Neuroscience},
	abstract = {The low-threshold calcium current (IT) underlies burst generation in thalamocortical (TC) relay cells and plays a central role in the genesis of synchronized oscillations by thalamic circuits. Here we have combined in vitro recordings and computational modeling techniques to investigate the consequences of dendritically locatedIT in TC cells. Simulations of a reconstructed TC cell were compared with the recordings obtained in the same cell to constrain the values of its passive parameters. T-current densities in soma and proximal dendrites were then estimated by matching the model to voltage-clamp recordings obtained in dissociated TC cells, which lack most of the dendrites. The distal dendritic T-current density was constrained by recordings in intact TC cells, which show 5{\textendash}14 times larger peak T-current amplitudes compared with dissociated cells. Comparison of the model with the recordings of the same cell constrained further the T-current density in dendrites, which had to be 4.5{\textendash}7.6 times higher than in the soma to reproduce all experimental results. Similar conclusions were reached using a simplified three-compartment model. Functionally, the model shows that the same amount of T-channels can lead to different bursting behaviors if they are exclusively somatic or distributed throughout the dendrites. In conclusion, this combination of models and experiments shows that dendritic T-currents are necessary to reproduce low-threshold calcium electrogenesis in TC cells. Dendritic T-current may also have significant functional consequences, such as an efficient modulation of thalamic burst discharges by corticothalamic feedback.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/18/10/3574},
	eprint = {https://www.jneurosci.org/content/18/10/3574.full.pdf},
	journal = {Journal of Neuroscience}
}

@article{Ermentrout,
 ISSN = {00361399},
 URL = {http://www.jstor.org/stable/2101582},
 abstract = {We investigate the interaction of an excitable system with a slow oscillation. Under robust and general assumptions compatible with the more stringent assumptions usually made about excitable systems, we show that such a coupled system can display bursting, i.e. a stable solution in which some variable undergoes rapid oscillations followed by a period of quiescence, with both oscillation and quiescence continually repeated. Under a further weak condition, the bursting is "parabolic", i.e. the local frequency of the fast oscillation increases and then decreases within a burst. The technique in this paper involves nonlinear changes of coordinates which transform the equations into ones which are closely related to Hill's equation.},
 author = {G. B. Ermentrout and N. Kopell},
 journal = {SIAM Journal on Applied Mathematics},
 number = {2},
 pages = {233--253},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Parabolic Bursting in an Excitable System Coupled with a Slow Oscillation},
 urldate = {2023-12-01},
 volume = {46},
 year = {1986}
}

@ARTICLE{KohnoR,
AUTHOR={Kohno, Takashi and Sekikawa, Munehisa and Li, Jing and Nanami, Takuya and Aihara, Kazuyuki},    
TITLE={Qualitative-Modeling-Based Silicon Neurons and Their Networks},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={10},           
YEAR={2016},       
URL={https://www.frontiersin.org/articles/10.3389/fnins.2016.00273},       
DOI={10.3389/fnins.2016.00273},      
ISSN={1662-453X},   
ABSTRACT={The ionic conductance models of neuronal cells can finely reproduce a wide variety of complex neuronal activities. However, the complexity of these models has prompted the development of qualitative neuron models. They are described by differential equations with a reduced number of variables and their low-dimensional polynomials, which retain the core mathematical structures. Such simple models form the foundation of a bottom-up approach in computational and theoretical neuroscience. We proposed a qualitative-modeling-based approach for designing silicon neuron circuits, in which the mathematical structures in the polynomial-based qualitative models are reproduced by differential equations with silicon-native expressions. This approach can realize low-power-consuming circuits that can be configured to realize various classes of neuronal cells. In this article, our qualitative-modeling-based silicon neuron circuits for analog and digital implementations are quickly reviewed. One of our CMOS analog silicon neuron circuits can realize a variety of neuronal activities with a power consumption less than 72 nW. The square-wave bursting mode of this circuit is explained. Another circuit can realize Class I and II neuronal activities with about 3 nW. Our digital silicon neuron circuit can also realize these classes. An auto-associative memory realized on an all-to-all connected network of these silicon neurons is also reviewed, in which the neuron class plays important roles in its performance.}
}

@Inbook{Bower,
author="Bower, James M. and Cornelis, Hugo and Beeman, David",
title="GENESIS, The GEneral NEural SImulation System",
bookTitle="Encyclopedia of Computational Neuroscience",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="1--8",
isbn="978-1-4614-7320-6",
doi="10.1007/978-1-4614-7320-6_255-1",
url="https://doi.org/10.1007/978-1-4614-7320-6_255-1" }

@book{carnevale, 
place={Cambridge}, 
title={The NEURON Book}, 
DOI={10.1017/CBO9780511541612}, 
publisher={Cambridge University Press}, 
author={Carnevale, Nicholas T. and Hines, Michael L.}, 
year={2006}}

@article{Gewaltig,
author = {Gewaltig, Marc-Oliver and Diesmann, Markus},
year = {2007},
month = {01},
pages = {1430},
title = {NEST (neural simulation tool)},
volume = {2},
isbn = {978-1-4614-7320-6},
journal = {Scholarpedia},
doi = {10.4249/scholarpedia.1430}
}

@article{Walter,
author = {Walter, Florian and Röhrbein, Florian and Knoll, Alois},
year = {2016},
month = {08},
pages = {},
title = {Computation by Time},
volume = {44},
journal = {Neural Processing Letters},
doi = {10.1007/s11063-015-9478-6}
}

@ARTICLE{Goodman,
AUTHOR={Goodman, Dan and Brette, Romain},   
TITLE={Brian: a simulator for spiking neural networks in Python},      
JOURNAL={Frontiers in Neuroinformatics},      
VOLUME={2},           
YEAR={2008},      
URL={https://www.frontiersin.org/articles/10.3389/neuro.11.005.2008},       
DOI={10.3389/neuro.11.005.2008},      
ISSN={1662-5196},   
ABSTRACT={“Brian” is a new simulator for spiking neural networks, written in Python (http://brian. di.ens.fr). It is an intuitive and highly flexible tool for rapidly developing new models, especially networks of single-compartment neurons. In addition to using standard types of neuron models, users can define models by writing arbitrary differential equations in ordinary mathematical notation. Python scientific libraries can also be used for defining models and analysing data. Vectorisation techniques allow efficient simulations despite the overheads of an interpreted language. Brian will be especially valuable for working on non-standard neuron models not easily covered by existing software, and as an alternative to using Matlab or C for simulations. With its easy and intuitive syntax, Brian is also very well suited for teaching computational neuroscience.}
}

@article{Zenke,
author = {Zenke, Friedemann and Gerstner, Wulfram},
year = {2014},
month = {09},
pages = {76},
title = {Limits to high-speed simulations of spiking neural networks using general-purpose computers},
volume = {8},
journal = {Frontiers in neuroinformatics},
doi = {10.3389/fninf.2014.00076}
}

@ARTICLE{Panagiotou,
AUTHOR={Panagiotou, Sotirios and Sidiropoulos, Harry and Soudris, Dimitrios and Negrello, Mario and Strydis, Christos},   
TITLE={EDEN: A High-Performance, General-Purpose, NeuroML-Based Neural Simulator},      
JOURNAL={Frontiers in Neuroinformatics},      
VOLUME={16},           
YEAR={2022},      
URL={https://www.frontiersin.org/articles/10.3389/fninf.2022.724336},       
DOI={10.3389/fninf.2022.724336},      
ISSN={1662-5196},   
ABSTRACT={Modern neuroscience employs in silico experimentation on ever-increasing and more detailed neural networks. The high modeling detail goes hand in hand with the need for high model reproducibility, reusability and transparency. Besides, the size of the models and the long timescales under study mandate the use of a simulation system with high computational performance, so as to provide an acceptable time to result. In this work, we present EDEN (Extensible Dynamics Engine for Networks), a new general-purpose, NeuroML-based neural simulator that achieves both high model flexibility and high computational performance, through an innovative model-analysis and code-generation technique. The simulator runs NeuroML-v2 models directly, eliminating the need for users to learn yet another simulator-specific, model-specification language. EDEN's functional correctness and computational performance were assessed through NeuroML models available on the NeuroML-DB and Open Source Brain model repositories. In qualitative experiments, the results produced by EDEN were verified against the established NEURON simulator, for a wide range of models. At the same time, computational-performance benchmarks reveal that EDEN runs from one to nearly two orders-of-magnitude faster than NEURON on a typical desktop computer, and does so without additional effort from the user. Finally, and without added user effort, EDEN has been built from scratch to scale seamlessly over multiple CPUs and across computer clusters, when available.}
}

@article{Yavuz,
author = {Yavuz, Esin and Turner, James and Nowotny, Thomas},
year = {2016},
month = {01},
pages = {18854},
title = {GeNN: A code generation framework for accelerated brain simulations},
volume = {6},
journal = {Scientific Reports},
doi = {10.1038/srep18854}
}

@article {Stimberg,
article_type = {journal},
title = {Brian 2, an intuitive and efficient neural simulator},
author = {Stimberg, Marcel and Brette, Romain and Goodman, Dan FM},
editor = {Skinner, Frances K and Calabrese, Ronald L and Skinner, Frances K and Zeldenrust, Fleur and Gerkin, Richard C},
volume = 8,
year = 2019,
month = {09},
pub_date = {2019-08-20},
pages = {e47314},
citation = {eLife 2019;8:e47314},
doi = {10.7554/eLife.47314},
url = {https://doi.org/10.7554/eLife.47314},
abstract = {Brian 2 allows scientists to simply and efficiently simulate spiking neural network models. These models can feature novel dynamical equations, their interactions with the environment, and experimental protocols. To preserve high performance when defining new models, most simulators offer two options: low-level programming or description languages. The first option requires expertise, is prone to errors, and is problematic for reproducibility. The second option cannot describe all aspects of a computational experiment, such as the potentially complex logic of a stimulation protocol. Brian addresses these issues using runtime code generation. Scientists write code with simple and concise high-level descriptions, and Brian transforms them into efficient low-level code that can run interleaved with their code. We illustrate this with several challenging examples: a plastic model of the pyloric network, a closed-loop sensorimotor model, a programmatic exploration of a neuron model, and an auditory model with real-time input.},
keywords = {computational neuroscience, simulation, software},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@ARTICLE{Qiao,
AUTHOR={Qiao, Ning and Mostafa, Hesham and Corradi, Federico and Osswald, Marc and Stefanini, Fabio and Sumislawska, Dora and Indiveri, Giacomo},   
TITLE={A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128K synapses},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={9},           
YEAR={2015},        
URL={https://www.frontiersin.org/articles/10.3389/fnins.2015.00141},       
DOI={10.3389/fnins.2015.00141},      
ISSN={1662-453X},   
ABSTRACT={Implementing compact, low-power artificial neural processing systems with real-time on-line learning abilities is still an open challenge. In this paper we present a full-custom mixed-signal VLSI device with neuromorphic learning circuits that emulate the biophysics of real spiking neurons and dynamic synapses for exploring the properties of computational neuroscience models and for building brain-inspired computing systems. The proposed architecture allows the on-chip configuration of a wide range of network connectivities, including recurrent and deep networks, with short-term and long-term plasticity. The device comprises 128 K analog synapse and 256 neuron circuits with biologically plausible dynamics and bi-stable spike-based plasticity mechanisms that endow it with on-line learning abilities. In addition to the analog circuits, the device comprises also asynchronous digital logic circuits for setting different synapse and neuron properties as well as different network configurations. This prototype device, fabricated using a 180 nm 1P6M CMOS process, occupies an area of 51.4 mm<sup>2</sup>, and consumes approximately 4 mW for typical experiments, for example involving attractor networks. Here we describe the details of the overall architecture and of the individual circuits and present experimental results that showcase its potential. By supporting a wide range of cortical-like computational modules comprising plasticity mechanisms, this device will enable the realization of intelligent autonomous systems with on-line learning capabilities.}
}

@article{Moradi,
author = {Moradi, Saber and Qiao, Ning and Stefanini, Fabio and Indiveri, Giacomo},
year = {2017},
month = {08},
pages = {},
title = {A Scalable Multicore Architecture With Heterogeneous Memory Structures for Dynamic Neuromorphic Asynchronous Processors (DYNAPs)},
volume = {PP},
journal = {IEEE Transactions on Biomedical Circuits and Systems},
doi = {10.1109/TBCAS.2017.2759700}
}

@article{Benjamin,
  title={Neurogrid: A Mixed-Analog-Digital Multichip System for Large-Scale Neural Simulations},
  author={Ben Varkey Benjamin and Peiran Gao and Emmett McQuinn and Swadesh Choudhary and Anand Chandrasekaran and Jean-Marie Bussat and Rodrigo Alvarez-Icaza and John V. Arthur and Paul Merolla and Kwabena A. Boahen},
  journal={Proceedings of the IEEE},
  year={2014},
  volume={102},
  pages={699-716},
  url={https://api.semanticscholar.org/CorpusID:17176371}
}

@article{Seo,
author = {Seo, Jae-sun and Brezzo, Bernard and Liu, Yong and Parker, Brent and Esser, S.K. and Montoye, Robert and Rajendran, Bipin and Tierno, Jose and Chang, Leland and Modha, Dharmendra and Friedman, Daniel},
year = {2011},
month = {09},
pages = {1-4},
title = {A 45nm CMOS neuromorphic chip with a scalable architecture for learning in networks of spiking neurons},
journal = {Custom Integrated Circuits Conference (CICC), 2011 IEEE},
doi = {10.1109/CICC.2011.6055293}
}

@article{FrenkelOdin,
author = {Frenkel, Charlotte and Lefebvre, Martin and Legat, Jean-Didier and Bol, David},
year = {2019},
month = {02},
pages = {145-158},
title = {A 0.086-mm² 12.7-pJ/SOP 64k-Synapse 256-Neuron Online-Learning Digital Spiking Neuromorphic Processor in 28nm CMOS},
volume = {13},
journal = {IEEE Transactions on Biomedical Circuits and Systems},
doi = {10.1109/TBCAS.2018.2880425}
}

@article{FrenkelMorphic,
author = {Frenkel, Charlotte and Legat, Jean-Didier and Bol, David},
year = {2019},
month = {10},
pages = {999-1010},
title = {MorphIC: A 65-nm 738k-Synapse/mm 2 Quad-Core Binary-Weight Digital Neuromorphic Processor With Stochastic Spike-Driven Online Learning},
volume = {13},
journal = {IEEE Transactions on Biomedical Circuits and Systems},
doi = {10.1109/TBCAS.2019.2928793}
}

@ARTICLE{Painkras,
  author={Painkras, Eustace and Plana, Luis A. and Garside, Jim and Temple, Steve and Galluppi, Francesco and Patterson, Cameron and Lester, David R. and Brown, Andrew D. and Furber, Steve B.},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={SpiNNaker: A 1-W 18-Core System-on-Chip for Massively-Parallel Neural Network Simulation}, 
  year={2013},
  volume={48},
  number={8},
  pages={1943-1953},
  doi={10.1109/JSSC.2013.2259038}}

@article{Merolla,
doi={10.1126/science.1254642},
author = {Paul A. Merolla  and John V. Arthur  and Rodrigo Alvarez-Icaza  and Andrew S. Cassidy  and Jun Sawada  and Filipp Akopyan  and Bryan L. Jackson  and Nabil Imam  and Chen Guo  and Yutaka Nakamura  and Bernard Brezzo  and Ivan Vo  and Steven K. Esser  and Rathinakumar Appuswamy  and Brian Taba  and Arnon Amir  and Myron D. Flickner  and William P. Risk  and Rajit Manohar  and Dharmendra S. Modha },
title = {A million spiking-neuron integrated circuit with a scalable communication network and interface},
journal = {Science},
volume = {345},
number = {6197},
pages = {668-673},
year = {2014},
doi = {10.1126/science.1254642},
URL = {https://www.science.org/doi/abs/10.1126/science.1254642},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1254642},
abstract = {Computers are nowhere near as versatile as our own brains. Merolla et al. applied our present knowledge of the structure and function of the brain to design a new computer chip that uses the same wiring rules and architecture. The flexible, scalable chip operated efficiently in real time, while using very little power. Science, this issue p. 668 A large-scale computer chip mimics many features of a real brain. Inspired by the brain’s structure, we have developed an efficient, scalable, and flexible non–von Neumann architecture that leverages contemporary silicon technology. To demonstrate, we built a 5.4-billion-transistor chip with 4096 neurosynaptic cores interconnected via an intrachip network that integrates 1 million programmable spiking neurons and 256 million configurable synapses. Chips can be tiled in two dimensions via an interchip communication interface, seamlessly scaling the architecture to a cortexlike sheet of arbitrary size. The architecture is well suited to many applications that use complex neural networks in real time, for example, multiobject detection and classification. With 400-pixel-by-240-pixel video input at 30 frames per second, the chip consumes 63 milliwatts.}}

@article{Cassidy2013,
author = {Cassidy, Andrew and Merolla, Paul and Arthur, John and Esser, S.K. and Jackson, Bryan and Alvarez-Icaza, Rodrigo and Datta, Pallab and Sawada, Jun and Wong, Theodore and Feldman, Vitaly and Amir, Arnon and Ben Dayan Rubin, Daniel and Akopyan, Filipp and McQuinn, Emmett and Risk, W.P. and Modha, Dharmendra},
year = {2013},
month = {08},
pages = {},
title = {Cognitive computing building block: A versatile and efficient digital neuron model for neurosynaptic cores},
journal = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2013.6707077}
}

@article{Davies,
author = {Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Joshi, Prasad and Lines, Andrew and Wild, Andreas and Wang, Hong and Mathaikutty, Deepak},
year = {2018},
month = {01},
pages = {1-1},
title = {Loihi: A Neuromorphic Manycore Processor with On-Chip Learning},
volume = {PP},
journal = {IEEE Micro},
doi = {10.1109/MM.2018.112130359}
}

@article{Thomas,
author = {Thomas, David and Luk, Wayne},
year = {2009},
month = {01},
pages = {45-52},
title = {FPGA Accelerated Simulation of Biologically Plausible Spiking Neural Networks},
journal = {17th IEEE Symposium on Field Programmable Custom Computing Machines},
doi = {10.1109/FCCM.2009.46}
}

@ARTICLE{Li2012,
AUTHOR={Li, Jing and Katori, Yuichi and Kohno, Takashi},   
TITLE={An FPGA-Based Silicon Neuronal Network with Selectable Excitability Silicon Neurons},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={6},           
YEAR={2012},      
URL={https://www.frontiersin.org/articles/10.3389/fnins.2012.00183},       
DOI={10.3389/fnins.2012.00183},      
ISSN={1662-453X},   
ABSTRACT={This paper presents a digital silicon neuronal network which simulates the nerve system in creatures and has the ability to execute intelligent tasks, such as associative memory. Two essential elements, the mathematical-structure-based digital spiking silicon neuron (DSSN) and the transmitter release based silicon synapse, allow us to tune the excitability of silicon neurons and are computationally efficient for hardware implementation. We adopt mixed pipeline and parallel structure and shift operations to design a sufficient large and complex network without excessive hardware resource cost. The network with 256 full-connected neurons is built on a Digilent Atlys board equipped with a Xilinx Spartan-6 LX45 FPGA. Besides, a memory control block and USB control block are designed to accomplish the task of data communication between the network and the host PC. This paper also describes the mechanism of associative memory performed in the silicon neuronal network. The network is capable of retrieving stored patterns if the inputs contain enough information of them. The retrieving probability increases with the similarity between the input and the stored pattern increasing. Synchronization of neurons is observed when the successful stored pattern retrieval occurs.}
}

@article{Neil,
author = {Neil, Dan},
year = {2014},
month = {01},
pages = {1},
title = {Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator},
volume = {PP},
journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
doi = {10.1109/TVLSI.2013.2294916}
}

@article{Luo,
author = {Luo, Junwen and Coapes, Graeme and Mak, Terrence and Yamazaki, Tadashi and Tin, Chung and Degenaar, Patrick},
year = {2015},
month = {10},
pages = {},
title = {Real-Time Simulation of Passage-of-Time Encoding in Cerebellum Using a Scalable FPGA-Based System},
volume = {10},
journal = {IEEE transactions on biomedical circuits and systems},
doi = {10.1109/TBCAS.2015.2460232}
}

@article{Khoyratee,
author = {Khoyratee, Farad and Grassia, Filippo and Saïghi, Sylvain and Levi, Timothée},
year = {2019},
month = {04},
pages = {},
title = {Optimized Real-Time Biomimetic Neural Network on FPGA for Bio-hybridization},
volume = {13},
journal = {Frontiers in Neuroscience},
doi = {10.3389/fnins.2019.00377}
}

@article{Yang,
author = {Yang, Shuangming and Wang, Jiang and deng, Bin and Liu, Chen and Li, Huiyan and Fietkiewicz, Chris and Loparo, Kenneth},
year = {2019},
month = {04},
pages = {2490-2503},
title = {Real-Time Neuromorphic System for Large-Scale Conductance-Based Spiking Neural Networks},
volume = {49},
journal = {IEEE Transactions on Cybernetics},
doi = {10.1109/TCYB.2018.2823730}
}

@article{DESTEXHE,
title = {LTS cells in cerebral cortex and their role in generating spike-and-wave oscillations},
journal = {Neurocomputing},
volume = {38-40},
pages = {555-563},
year = {2001},
note = {Computational Neuroscience: Trends in Research 2001},
issn = {0925-2312},
doi = {https://doi.org/10.1016/S0925-2312(01)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0925231201003484},
author = {Alain Destexhe and Diego Contreras and Mircea Steriade},
keywords = {Epileptic seizures, Rebound burst, LTS, GABA},
abstract = {Some types of epileptic seizures involve both thalamus and cerebral cortex, while other types can be evoked in the cerebral cortex without thalamic participation. We investigated the possible role of low-threshold spike (LTS) cortical neurons in the genesis of these intracortical seizures. We found LTS cortical neurons in cat area 5–7 in vivo, the properties of which could be modeled based on relatively weak densities of the T-type calcium channel. At the network level, a small minority of LTS pyramidal cells was sufficient to generate paroxysmal oscillations with spike-and-wave (SW) field potentials. These oscillations reproduce the properties of intracortical SW paroxysms observed in athalamic cats, such as the slow frequency (1.8–2.5Hz). We suggest that calcium-mediated rebound mechanisms intrinsic to cerebral cortex can explain the genesis of intracortical SW activity.}
}

@article{Stein,
author = {Stein, R.B. and Gossen, E.R. and Jones, Kelvin},
year = {2005},
month = {01},
pages = {389-397},
title = {Neuronal variability: Noise or part of the signal?},
volume = {6},
journal = {Nature Reviews Neuroscience}
}

@article{Urban,
author = {Urban, Nathaniel and Tripathy, Shreejoy},
year = {2012},
month = {08},
pages = {289-90},
title = {Neuroscience: Circuits drive cell diversity},
volume = {488},
journal = {Nature},
doi = {10.1038/488289a}
}

@article{Balasubramanian,
author = {Balasubramanian, Vijay},
year = {2015},
month = {08},
pages = {1346-1358},
title = {Heterogeneity and Efficiency in the Brain},
volume = {103},
journal = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2015.2447016}
}

@article{Perez-Nievez,
author = {Perez-Nieves, Nicolas and Leung, Vincent and Dragotti, Pier and Goodman, Dan},
year = {2021},
month = {10},
pages = {5791},
title = {Neural heterogeneity promotes robust learning},
volume = {12},
journal = {Nature Communications},
doi = {10.1038/s41467-021-26022-3}
}

@article{Zendrikov,
author = {Zendrikov, Dmitrii and Solinas, Sergio and Indiveri, Giacomo},
year = {2023},
month = {07},
pages = {},
title = {Brain-inspired methods for achieving robust computation in heterogeneous mixed-signal neuromorphic processing systems},
volume = {3},
journal = {Neuromorphic Computing and Engineering},
doi = {10.1088/2634-4386/ace64c}
}

@inproceedings{SchultePillmeier,
  title={Design alternatives for barrel shifters},
  author={Matthew Rudolf Pillmeier and Michael J. Schulte and E. George Walters},
  booktitle={SPIE Optics + Photonics},
  year={2002},
  url={https://api.semanticscholar.org/CorpusID:8000871}
}

@article{Mahowald,
author = {Mahowald, Misha},
year = {2011},
month = {07},
pages = {4-65},
title = {The Silicon Retina},
volume = {264},
isbn = {978-1-4613-6174-9},
journal = {Sci. Am.},
doi = {10.1007/978-1-4615-2724-4_2}
}

@ARTICLE{Lyon,
  author={Lyon, R.F. and Mead, C.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={An analog electronic cochlea}, 
  year={1988},
  volume={36},
  number={7},
  pages={1119-1134},
  doi={10.1109/29.1639}}

@article{Corradi,
author = {Corradi, Federico and Zambrano, Davide and Raglianti, Marco and Passetti, Giovanni and Laschi, Cecilia and Indiveri, Giacomo},
year = {2014},
month = {10},
pages = {1},
title = {Towards a Neuromorphic Vestibular System},
volume = {PP},
journal = {IEEE Transactions on Biomedical Circuits and Systems},
doi = {10.1109/TBCAS.2014.2358493}
}

@article{Koickal,
author = {Koickal, Thomas and Hamilton, Alister and Tan, Su and Covington, James and Gardner, J.W. and Pearce, Tim},
year = {2007},
month = {02},
pages = {60 - 73},
title = {Analog VLSI Circuit Implementation of an Adaptive Neuromorphic Olfaction Chip},
volume = {54},
journal = {Circuits and Systems I: Regular Papers, IEEE Transactions on},
doi = {10.1109/TCSI.2006.888677}
}

@article{Bartolozzi,
author = {Bartolozzi, Chiara},
year = {2018},
month = {06},
pages = {966-967},
title = {Neuromorphic circuits impart a sense of touch},
volume = {360},
journal = {Science (New York, N.Y.)},
doi = {10.1126/science.aat3125}
}

@article{Yamazaki,
author = {Yamazaki, Kashu and Vo, Khoa and Bulsara, Darshan},
year = {2022},
month = {06},
pages = {},
title = {Spiking Neural Networks and Their Applications: A Review},
volume = {12},
journal = {Brain sciences},
doi = {10.3390/brainsci12070863}
}

@article{Katz,
author = {Katz, Paul},
year = {2016},
month = {01},
pages = {20150057},
title = {Evolution of central pattern generators and rhythmic behaviours},
volume = {371},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
doi = {10.1098/rstb.2015.0057}
}

@article{Ecker,
author = {Ecker, András and Romani, Armando and Sáray, Sára and Káli, Szabolcs and Migliore, Michele and Falck, Joanne and Lange, Sigrun and Mercer, Audrey and Thomson, Alex and Muller, Eilif and Reimann, Michael and Ramaswamy, Srikanth},
year = {2020},
month = {06},
pages = {},
title = {Data‐driven integration of hippocampal CA1 synaptic physiology in silico},
volume = {30},
journal = {Hippocampus},
doi = {10.1002/hipo.23220}
}

@article {Bezaire,
article_type = {journal},
title = {Interneuronal mechanisms of hippocampal theta oscillations in a full-scale model of the rodent CA1 circuit},
author = {Bezaire, Marianne J and Raikov, Ivan and Burk, Kelly and Vyas, Dhrumil and Soltesz, Ivan},
editor = {Skinner, Frances K},
volume = 5,
year = 2016,
month = {12},
pub_date = {2016-12-23},
pages = {e18566},
citation = {eLife 2016;5:e18566},
doi = {10.7554/eLife.18566},
url = {https://doi.org/10.7554/eLife.18566},
abstract = {The hippocampal theta rhythm plays important roles in information processing; however, the mechanisms of its generation are not well understood. We developed a data-driven, supercomputer-based, full-scale (1:1) model of the rodent CA1 area and studied its interneurons during theta oscillations. Theta rhythm with phase-locked gamma oscillations and phase-preferential discharges of distinct interneuronal types spontaneously emerged from the isolated CA1 circuit without rhythmic inputs. Perturbation experiments identified parvalbumin-expressing interneurons and neurogliaform cells, as well as interneuronal diversity itself, as important factors in theta generation. These simulations reveal new insights into the spatiotemporal organization of the CA1 circuit during theta oscillations.},
keywords = {computational, inhibition, hippocampus, model network, oscillation, theta},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{Markram,
author = {Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Guy Antoine, Atenekeng Kahou and Berger, Thomas K and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean-Denis and Delalondre, Fabien and Delattre, Vincent and Schürmann, Felix},
year = {2015},
month = {10},
pages = {456-492},
title = {Reconstruction and Simulation of Neocortical Microcircuitry},
volume = {163},
journal = {Cell},
doi = {10.1016/j.cell.2015.09.029}
}

@article{Jung,
author = {Jung, Ranu and Brauer, Elizabeth and Abbas, James},
year = {2001},
month = {10},
pages = {319-26},
title = {Real-Time Interaction Between a Neuromorphic Electronic Circuit and the Spinal Cord},
volume = {9},
journal = {IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society},
doi = {10.1109/7333.948461}
}

@article{Chiappalone,
author = {Chiappalone, Michela and Cota, Vinicius and Carè, Marta and Florio, Mattia and Beaubois, Romain and Buccelli, Stefano and Barban, Federico and Brofiga, Martina and Averna, Alberto and Bonacini, Francesco and Guggenmos, David and Bornat, Yannick and Massobrio, Paolo and Bonifazi, Paolo and Levi, Timothée},
year = {2022},
month = {11},
pages = {1578},
title = {Neuromorphic-Based Neuroprostheses for Brain Rewiring: State-of-the-Art and Perspectives in Neuroengineering},
volume = {12},
journal = {Brain Sciences},
doi = {10.3390/brainsci12111578}
}

@article{GEORGE,
title = {Plasticity and Adaptation in Neuromorphic Biohybrid Systems},
journal = {iScience},
volume = {23},
number = {10},
pages = {101589},
year = {2020},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2020.101589},
url = {https://www.sciencedirect.com/science/article/pii/S2589004220307811},
author = {Richard George and Michela Chiappalone and Michele Giugliano and Timothée Levi and Stefano Vassanelli and Johannes Partzsch and Christian Mayr},
keywords = {Neuroscience, Bioengineering, Computer Hardware, Computing Methodology},
abstract = {Summary
Neuromorphic systems take inspiration from the principles of biological information processing to form hardware platforms that enable the large-scale implementation of neural networks. The recent years have seen both advances in the theoretical aspects of spiking neural networks for their use in classification and control tasks and a progress in electrophysiological methods that is pushing the frontiers of intelligent neural interfacing and signal processing technologies. At the forefront of these new technologies, artificial and biological neural networks are tightly coupled, offering a novel “biohybrid” experimental framework for engineers and neurophysiologists. Indeed, biohybrid systems can constitute a new class of neuroprostheses opening important perspectives in the treatment of neurological disorders. Moreover, the use of biologically plausible learning rules allows forming an overall fault-tolerant system of co-developing subsystems. To identify opportunities and challenges in neuromorphic biohybrid systems, we discuss the field from the perspectives of neurobiology, computational neuroscience, and neuromorphic engineering.}
}

@article{LEMASSON,
title = {From conductances to neural network properties: Analysis of simple circuits using the hybrid network method},
journal = {Progress in Biophysics and Molecular Biology},
volume = {64},
number = {2},
pages = {201-220},
year = {1995},
issn = {0079-6107},
doi = {https://doi.org/10.1016/S0079-6107(96)00004-1},
url = {https://www.sciencedirect.com/science/article/pii/S0079610796000041},
author = {Gwendal {Le Masson} and Sylvie {Le Masson} and Maurice Moulins}
}

@ARTICLE{Joucla,
AUTHOR={Joucla, Sébastien and Ambroise, Matthieu and Levi, Timothée and Lafon, Thierry and Chauvet, Philippe and Saïghi, Sylvain and Bornat, Yannick and Lewis, Noëlle and Renaud, Sylvie and Yvert, Blaise},   
TITLE={Generation of Locomotor-Like Activity in the Isolated Rat Spinal Cord Using Intraspinal Electrical Microstimulation Driven by a Digital Neuromorphic CPG},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={10},           
YEAR={2016},        
URL={https://www.frontiersin.org/articles/10.3389/fnins.2016.00067},       
DOI={10.3389/fnins.2016.00067},      
ISSN={1662-453X},   
ABSTRACT={Neural prostheses based on electrical microstimulation offer promising perspectives to restore functions following lesions of the central nervous system (CNS). They require the identification of appropriate stimulation sites and the coordination of their activation to achieve the restoration of functional activity. On the long term, a challenging perspective is to control microstimulation by artificial neural networks hybridized to the living tissue. Regarding the use of this strategy to restore locomotor activity in the spinal cord, to date, there has been no proof of principle of such hybrid approach driving intraspinal microstimulation (ISMS). Here, we address a first step toward this goal in the neonatal rat spinal cord isolated ex vivo, which can display locomotor-like activity while offering an easy access to intraspinal circuitry. Microelectrode arrays were inserted in the lumbar region to determine appropriate stimulation sites to elicit elementary bursting patterns on bilateral L2/L5 ventral roots. Two intraspinal sites were identified at L1 level, one on each side of the spinal cord laterally from the midline and approximately at a median position dorso-ventrally. An artificial CPG implemented on digital integrated circuit (FPGA) was built to generate alternating activity and was hybridized to the living spinal cord to drive electrical microstimulation on these two identified sites. Using this strategy, sustained left-right and flexor-extensor alternating activity on bilateral L2/L5 ventral roots could be generated in either whole or thoracically transected spinal cords. These results are a first step toward hybrid artificial/biological solutions based on electrical microstimulation for the restoration of lost function in the injured CNS.}
}

@article{MAASS,
title = {Networks of spiking neurons: The third generation of neural network models},
journal = {Neural Networks},
volume = {10},
number = {9},
pages = {1659-1671},
year = {1997},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(97)00011-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608097000117},
author = {Wolfgang Maass},
keywords = {Spiking neuron, Integrate-and-fire neutron, Computational complexity, Sigmoidal neural nets, Lower bounds},
abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology.}
}

@article{McCulloch,
  title={McCulloch Warren S. and Pitts Walter. A logical calculus of the ideas immanent in nervous activity. Bulletin of mathematical biophysics, vol. 5 , pp. 115–133},
  author={ Fitch, Frederic B. },
  journal={Journal of Symbolic Logic},
  volume={9},
  number={2},
  pages={49-50},
  year={2014},
}

@article{Nair,
author = {Nair, Vinod and Hinton, Geoffrey},
year = {2010},
month = {06},
pages = {807-814},
title = {Rectified Linear Units Improve Restricted Boltzmann Machines Vinod Nair},
volume = {27},
journal = {Proceedings of ICML}
}

@article{Sharma,
author = {Sharma, Sachin and Kumar, Gaurav and Mishra, Dipak and Mohapatra, Debasis},
year = {2012},
month = {02},
pages = {},
title = {Design and Implementation of a Variable Gain Amplifier for Biomedical Signal Acquisition},
journal = {international journal of advanced research in Computer science and software engineering}
}

@article{Hansel,
  title = {Synchrony in excitatory neural networks},
  author = {David Hansel and Germán Mato and Claude Meunier},
  year = {1995},
  url = {http://neco.mitpress.org/cgi/content/abstract/7/2/307},
  researchr = {https://researchr.org/publication/HanselMM95},
  cites = {0},
  citedby = {0},
  journal = {Neural Computation},
  volume = {7},
  number = {2},
  pages = {307-337},
}

@book{Dally,
author = {Dally, William J. and Harting, R. Curtis and Aamodt, Tor M.},
title = {Digital Design Using VHDL: A Systems Approach},
year = {2016},
isbn = {1107098866},
publisher = {Cambridge University Press},
address = {USA},
edition = {1st},
abstract = {This introductory textbook provides students with a system-level perspective and the tools they need to understand, analyze and design digital systems. Going beyond the design of simple combinational and sequential modules, it shows how such modules are used to build complete systems, reflecting real-world digital design. All the essential topics are covered, including design and analysis of combinational and sequential modules, as well as system timing and synchronization. It also teaches how to write VHDL-2008 HDL in a productive and maintainable style that enables CAD tools to do much of the tedious work. A complete introduction to digital design is given through clear explanations, extensive examples and online VHDL files. The teaching package is completed with lecture slides, labs and a solutions manual for instructors. Assuming no previous digital knowledge, this textbook is ideal for undergraduate digital design courses that will prepare students for modern digital practice.}
}

@book{RapidPrototyping,
author = {Hamblen, James O. and Hall, Tyson S. and Furman, Michael D.},
title = {Rapid Prototyping of Digital Systems: SOPC Edition},
year = {2007},
isbn = {0387726705},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {New to this edition is an introduction to embedded operating systems for SOPC designs. The Clinux OS is configured for Altera's DE1 and DE2 boards and is provided ona DVD along with several application programs. Featuring four accelerated tutorials on the Quartus II and Nios II design environments, this edition progresses from introductory programmable logic to full-scale SOPC design integrating hardware implementation, software development, operating system support, state-of-the-art I/O, and IP cores. This edition features Altera's new 7.1 Quartus II CAD and Nios II SOPC tools and includes projects for Altera's DE1, DE2, UP3, UP2, and UP1 FPGA development boards. Laboratory projects provided on the book's DVD include complete projects for video graphics and text, mouse and keyboard input, and three separate computer examples including a Nios II "reference" design for the DE2, DE1, and UP3 FPGA boards.}
}

@book{Mead1989,
  title={Analog VLSI and Neural Systems},
  author={Mead, C.},
  isbn={9780201059922},
  lccn={lc88014635},
  series={Addison-Wesley VLSI system series},
  url={https://books.google.it/books?id=-j8PAQAAMAAJ},
  year={1989},
  publisher={Addison-Wesley}
}

@inproceedings{NanamiNov2016,
author = {Nanami, Takuya and Aihara, Kazuyuki and Kohno, Takashi},
year = {2016},
booktitle = {International Symposium on Nonlinear Theory and Its Applications,
NOLTA2016},
month = {11},
pages = {},
title = {Elliptic and parabolic bursting in a digital silicon neuron model}
}

@inproceedings{Kohno2007,
author = {Kohno, Takashi and Aihara, Kazuyuki},
year = {2007},
month = {01},
pages = {},
booktitle = {International Symposium on Artificial Life and Robotics 2007},
title = {Digital Spiking Silicon Neuron: Concept and Behaviors in GJ-coupled Network}
}

@book{Koch2001,
author = {Koch, Christof and Segev, Idan},
year = {2001},
month = {01},
pages = {},
publisher = {MIT Press},
title = {Methods in Neural Modeling}
}

@ARTICLE{Vitay,
AUTHOR={Vitay, Julien and Dinkelbach, Helge and Hamker, Fred},   
TITLE={ANNarchy: a code generation approach to neural simulations on parallel hardware},      
JOURNAL={Frontiers in Neuroinformatics},      
VOLUME={9},           
YEAR={2015},      
URL={https://www.frontiersin.org/articles/10.3389/fninf.2015.00019},       
DOI={10.3389/fninf.2015.00019},      
ISSN={1662-5196},   
ABSTRACT={Many modern neural simulators focus on the simulation of networks of spiking neurons on parallel hardware. Another important framework in computational neuroscience, rate-coded neural networks, is mostly difficult or impossible to implement using these simulators. We present here the ANNarchy (Artificial Neural Networks architect) neural simulator, which allows to easily define and simulate rate-coded and spiking networks, as well as combinations of both. The interface in Python has been designed to be close to the PyNN interface, while the definition of neuron and synapse models can be specified using an equation-oriented mathematical description similar to the Brian neural simulator. This information is used to generate C++ code that will efficiently perform the simulation on the chosen parallel hardware (multi-core system or graphical processing unit). Several numerical methods are available to transform ordinary differential equations into an efficient C++code. We compare the parallel performance of the simulator to existing solutions.}
}

@INPROCEEDINGS{Cassidy2011,
  author={Cassidy, Andrew and Andreou, Andreas G. and Georgiou, Julius},
  booktitle={2011 45th Annual Conference on Information Sciences and Systems}, 
  title={Design of a one million neuron single FPGA neuromorphic system for real-time multimodal scene analysis}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/CISS.2011.5766099}}

@INPROCEEDINGS{Liu,
  author={Liu, Shih-Chii and van Schaik, Andre and Minch, Bradley A. and Delbruck, Tobi},
  booktitle={2010 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Event-based 64-channel binaural silicon cochlea with Q enhancement mechanisms}, 
  year={2010},
  volume={},
  number={},
  pages={2027-2030},
  doi={10.1109/ISCAS.2010.5537164}}

@article{MCCULLOCH1990,
title = {A logical calculus of the ideas immanent in nervous activity},
journal = {Bulletin of Mathematical Biology},
volume = {52},
number = {1},
pages = {99-115},
year = {1990},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80006-0},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800060},
author = {Warren S. McCulloch and Walter Pitts},
abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.}
}

@article{BUCCELLI,
title = {A Neuromorphic Prosthesis to Restore Communication in Neuronal Networks},
journal = {iScience},
volume = {19},
pages = {402-414},
year = {2019},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2019.07.046},
url = {https://www.sciencedirect.com/science/article/pii/S2589004219302731},
author = {Stefano Buccelli and Yannick Bornat and Ilaria Colombi and Matthieu Ambroise and Laura Martines and Valentina Pasquale and Marta Bisio and Jacopo Tessadori and Przemysław Nowak and Filippo Grassia and Alberto Averna and Mariateresa Tedesco and Paolo Bonifazi and Francesco Difato and Paolo Massobrio and Timothée Levi and Michela Chiappalone},
keywords = {Neuroscience, Systems Neuroscience, Computer Science, Evolvable Hardware, Electronic Materials},
abstract = {Summary
Recent advances in bioelectronics and neural engineering allowed the development of brain machine interfaces and neuroprostheses, capable of facilitating or recovering functionality in people with neurological disability. To realize energy-efficient and real-time capable devices, neuromorphic computing systems are envisaged as the core of next-generation systems for brain repair. We demonstrate here a real-time hardware neuromorphic prosthesis to restore bidirectional interactions between two neuronal populations, even when one is damaged or missing. We used in vitro modular cell cultures to mimic the mutual interaction between neuronal assemblies and created a focal lesion to functionally disconnect the two populations. Then, we employed our neuromorphic prosthesis for bidirectional bridging to artificially reconnect two disconnected neuronal modules and for hybrid bidirectional bridging to replace the activity of one module with a real-time hardware neuromorphic Spiking Neural Network. Our neuroprosthetic system opens avenues for the exploitation of neuromorphic-based devices in bioelectrical therapeutics for health care.}
}

@article{DOMINGUEZMORALES,
title = {Real-time detection of bursts in neuronal cultures using a neuromorphic auditory sensor and spiking neural networks},
journal = {Neurocomputing},
volume = {449},
pages = {422-434},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.109},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221005014},
author = {Juan P. Dominguez-Morales and Stefano Buccelli and Daniel Gutierrez-Galan and Ilaria Colombi and Angel Jimenez-Fernandez and Michela Chiappalone},
keywords = {SpiNNaker, Spiking neural networks, Neuromorphic hardware, Brain signals processing, Burst detection},
abstract = {The correct identification of burst events is crucial in many scenarios, ranging from basic neuroscience to biomedical applications. However, none of the burst detection methods that can be found in the literature have been widely adopted for this task. As an alternative to conventional techniques, a novel neuromorphic approach for real-time burst detection is proposed and tested on acquisitions from in vitro cultures. The system consists of a Neuromorphic Auditory Sensor, which converts the input signal obtained from electrophysiological recordings into spikes and decomposes them into different frequency bands. The output of the sensor is sent to a trained Spiking Neural Network implemented on a SpiNNaker board that discerns between bursting and non-bursting activity. This data-driven approach was compared with different conventional spike-based and raw-based burst detection methods, addressing some of their drawbacks, such as being able to detect both high and low frequency events and working in an online manner. Similar results in terms of number of detected events, mean burst duration and correlation as current state-of-the-art approaches were obtained with the proposed system, also benefiting from its lower power consumption and computational latency. Therefore, our neuromorphic-based burst detection paves the road to future implementations for real-time neuroprosthetic applications.}
}

@ARTICLE{LeviClosedLoop,
AUTHOR={Levi, Timothée and Bonifazi, Paolo and Massobrio, Paolo and Chiappalone, Michela},   
TITLE={Editorial: Closed-Loop Systems for Next-Generation Neuroprostheses},      
JOURNAL={Frontiers in Neuroscience},      
VOLUME={12},           
YEAR={2018},        
URL={https://www.frontiersin.org/articles/10.3389/fnins.2018.00026},       
DOI={10.3389/fnins.2018.00026},      
ISSN={1662-453X}  
}

@misc{CarverMead, 
title={Insight 1: Logic in Physical Form}, 
url={https://www.youtube.com/watch?v=txH3K3shIWs&t=67s}, 
journal={YouTube}, 
author={Carver Mead}, 
year={2018}, 
month={05},
note = "Accessed 12/23"
}

@misc{coursera,
author = {Scherr Timothy},
title = {Introduction to FPGA design for embedded systems},
howpublished = "\url{https://www.coursera.org/learn/intro-fpga-design-embedded-systems}",
year = {2011}, 
note = "Accessed 12/23"
}